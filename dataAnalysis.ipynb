{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports packages and assign variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "file_paths = [\n",
    "    'testData/1.10_A_30s_600ms_3/',\n",
    "    'testData/2.50_A_30s_600ms_3/',\n",
    "    'testData/3.90_A_30s_600ms_3/',\n",
    "    'testData/4.130_A_30s_600ms_3/',\n",
    "    'testData/5.60_A_30s_200ms_3/',\n",
    "    'testData/6.60_A_30s_500ms_3/',\n",
    "    'testData/7.60_A_30s_800ms_3/',\n",
    "    'testData/8.60_A_30s_1100ms_3/',\n",
    "    'testData/9.60_A_5s_600ms_3/',\n",
    "    'testData/10.60_A_20s_600ms_3/',\n",
    "    'testData/11.60_A_35s_600ms_3/',\n",
    "    'testData/12.60_A_50s_600ms_3/',\n",
    "    'testData/13.60_A_30s_600ms_2/',\n",
    "    'testData/14.60_A_30s_600ms_4/',\n",
    "    'testData/15.60_A_30s_600ms_6/',\n",
    "    'testData/16.60_A_30s_600ms_8/',\n",
    "    'testData/17.60_A_30s_600ms_3/',\n",
    "    'testData/18.60_A+NA+AZA_30s_600ms_3/',\n",
    "    'testData/19.60_A+NA_30s_600ms_3/',\n",
    "    'testData/20.60_A+AZA_30s_600ms_3/',\n",
    "    ]\n",
    "\n",
    "labels = [ _[12:-1] if _ [11] == '.' else _[11:-1] for _ in file_paths ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get mean time for endponits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'testCharts/meanTime'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "i = 1\n",
    "for path, label in zip(file_paths, labels):\n",
    "    marketlog = pd.read_csv(path + 'stockApp_marketlog.csv')\n",
    "    trafficlog = pd.read_csv(path + 'stockApp_trafficlog.csv')\n",
    "    merged_data = pd.merge(trafficlog,marketlog, on='request_id')\n",
    "    merged_data = merged_data[~merged_data['endpoint_url'].isin(['/api/signIn', '/api/signUp', '/api/addCompany'])]\n",
    "    average_times = merged_data.groupby('endpoint_url').agg({\n",
    "        'api_time': 'mean',\n",
    "        'application_time': 'mean',\n",
    "        'database_time': 'mean',\n",
    "        'request_id': 'count'\n",
    "    }).reset_index()\n",
    "\n",
    "    average_times.rename(columns={'request_id': 'count'}, inplace=True)\n",
    "    average_times['endpoint_label'] = average_times.apply(lambda row: f\"{row['endpoint_url'][4:]} \\n (requests: {row['count']})\", axis=1)\n",
    "    average_times =  average_times.drop(columns=['count'])\n",
    "    ax = average_times.plot(x='endpoint_label', kind='bar', figsize=(12, 8), width=0.8)\n",
    "    for j in ax.patches:\n",
    "        ax.annotate(f'{j.get_height():.4f}', \n",
    "                (j.get_x() + j.get_width() / 2, j.get_height()), \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    plt.xticks(rotation=0, ha='right', fontsize=8)\n",
    "    ax.set_xticklabels(average_times['endpoint_label'], rotation=0, ha='center', fontsize=8, wrap=True)\n",
    "    plt.xlabel('Endpoint URL')\n",
    "    plt.ylabel('Mean time (s)')\n",
    "    plt.title('Mean time | ' + label)\n",
    "    plt.grid(True)\n",
    "    plt.legend(title='Times')\n",
    "    plt.tight_layout()\n",
    "    file_name = f'{i}.{label}_plot.svg'\n",
    "    #plt.savefig(os.path.join(output_path, file_name))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean trade times for all companies in one cycle. Copmare test with the same changing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'testCharts/meanTimeTrade'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "group_size = [4,4,4,4,4]\n",
    "i = 0\n",
    "parametrs = ['user', 'request time', 'transaction time', 'number of transacion workers', 'user class','none',\n",
    "             'user', 'request time', 'transaction time', 'number of transacion workers']\n",
    "transactions_times = [30,30,30,30,30,30,30,30,5,20,35,50,30,30,30,30,30,30,30,30]\n",
    "start_idx = 0\n",
    "while start_idx < len(file_paths):\n",
    "    files_to_process = file_paths[start_idx:start_idx + group_size[i]]\n",
    "    labels_to_use = labels[start_idx:start_idx + group_size[i]]\n",
    "    parametr = parametrs[i]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    avg_application_times = []\n",
    "    avg_database_times = []\n",
    "    transactions_times_to_use = transactions_times[start_idx:start_idx +group_size[i]]\n",
    "    j = 0\n",
    "    for path, label in zip(files_to_process, labels_to_use):\n",
    "        tradelog = pd.read_csv(path + 'stockApp_tradelog.csv')\n",
    "        if 'company_ids' not in tradelog.columns:\n",
    "            print(f\"Brak kolumny 'company_ids' w danych: {label}\")\n",
    "            continue\n",
    "        grouped = tradelog.groupby('company_ids').agg({\n",
    "            'application_time': 'mean',\n",
    "            'database_time': 'mean'\n",
    "        }).reset_index()\n",
    "        avg_application_time = grouped['application_time'].sum() / transactions_times_to_use[j] * 100\n",
    "        avg_database_time = grouped['database_time'].sum() / transactions_times_to_use[j] * 100\n",
    "        avg_application_times.append(avg_application_time)\n",
    "        avg_database_times.append(avg_database_time)\n",
    "        j += 1\n",
    "    \n",
    "    x = range(len(files_to_process))\n",
    "    bar1 = plt.bar([_ - 0.2 for _ in x], avg_application_times, width=0.4, label='Application Time')\n",
    "    bar2 = plt.bar([_ + 0.2 for _ in x], avg_database_times, width=0.4, label='Database Time')\n",
    "    for bar in bar1:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "    for bar in bar2:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "    plt.xticks(ticks=[_ for _ in range(group_size[i])], labels=labels_to_use) \n",
    "    plt.ylabel('Average Time (%)')\n",
    "    plt.title(f'Mean transaction time | {parametr}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    file_name = f'{parametr}_plot.svg'\n",
    "    #plt.savefig(os.path.join(output_path, file_name))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    start_idx += group_size[i]\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response time over time test. Copmare test with the same changing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'testCharts/responseTime'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "group_sizes = [4,4,4,4,4]\n",
    "index = 0\n",
    "parametrs = ['user', 'request time', 'transaction time', 'number of transacion workers', 'user class','none',\n",
    "             'user', 'request time', 'transaction time', 'number of transacion workers']\n",
    "for i, size in enumerate(group_sizes):\n",
    "    files_to_process = file_paths[index:index + size]\n",
    "    labels_to_use = labels[index:index + size]\n",
    "    parametr = parametrs[i]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for path, label in zip(files_to_process, labels_to_use):\n",
    "        marketlog = pd.read_csv(path + 'stockApp_marketlog.csv')\n",
    "        trafficlog = pd.read_csv(path + 'stockApp_trafficlog.csv')\n",
    "        marketlog = marketlog.drop(columns='timestamp')\n",
    "        marketlog = pd.merge(marketlog, trafficlog, on='request_id')\n",
    "        marketlog = marketlog[~marketlog['endpoint_url'].isin(['/api/signIn', '/api/signUp', '/api/addCompany'])]\n",
    "        marketlog['timestamp'] = pd.to_datetime(marketlog['timestamp'])\n",
    "        marketlog = marketlog[['timestamp', 'api_time']] \n",
    "        start_time = marketlog['timestamp'].min()\n",
    "        marketlog['relative_time'] = (marketlog['timestamp'] - start_time).dt.total_seconds()\n",
    "        marketlog = marketlog.set_index('timestamp').resample('5s').mean().reset_index()\n",
    "        marketlog = marketlog.dropna()\n",
    "        plt.plot(marketlog['relative_time'], marketlog['api_time'], linestyle='-', label=label)\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('API Time (s)')\n",
    "    plt.title(f'API Time | {parametr}')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    file_name = f'{parametr}_api_time_plot.svg'\n",
    "    plt.show()\n",
    "    #plt.savefig(os.path.join(output_path, file_name))\n",
    "    plt.close()\n",
    "    index += size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade time over time. Copmare test with the same changing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'testCharts/tradeTime'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "group_sizes = [4,4,4,4,4]\n",
    "index = 0\n",
    "parametrs = ['user', 'request time', 'transaction time', 'number of transacion workers', 'user class','none',\n",
    "             'user', 'request time', 'transaction time', 'number of transacion workers']\n",
    "for i, size in enumerate(group_sizes):\n",
    "    files_to_process = file_paths[index:index + size]\n",
    "    labels_to_use = labels[index:index + size]\n",
    "    parametr = parametrs[i]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for path, label in zip(files_to_process, labels_to_use):\n",
    "        tradelog = pd.read_csv(path + 'stockApp_tradelog.csv')\n",
    "        tradelog['timestamp'] = pd.to_datetime(tradelog['timestamp'])\n",
    "        tradelog = tradelog[['timestamp', 'application_time']]\n",
    "        start_time = tradelog['timestamp'].min()\n",
    "        tradelog['relative_time'] = (tradelog['timestamp'] - start_time).dt.total_seconds()\n",
    "        tradelog = tradelog.sort_values(by='relative_time')\n",
    "        tradelog_resampled = tradelog.set_index('timestamp').resample('3s').mean().reset_index()\n",
    "        tradelog_resampled = tradelog_resampled.dropna()\n",
    "        tradelog_resampled.reset_index(inplace=True)\n",
    "        plt.plot(tradelog_resampled['relative_time'], tradelog_resampled['application_time'], linestyle='-', label=label)\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Mean time (s)')\n",
    "    plt.title('Mean transaction time | ' + parametr)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    file_name = f'{parametr}_plot.svg'\n",
    "    #plt.savefig(os.path.join(output_path, file_name))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    index += size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cpu charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, container_id):\n",
    "    file_path += 'stockApp_cpu.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    filtered_data = data[data['contener_id'] == container_id]\n",
    "    filtered_data = filtered_data[filtered_data['cpu_usage'] >= 3]\n",
    "    filtered_data['timestamp'] = pd.to_datetime(filtered_data['timestamp'])\n",
    "    start_time = filtered_data['timestamp'].min()\n",
    "    filtered_data = filtered_data[['timestamp', 'cpu_usage']]\n",
    "    filtered_data['relative_time'] = (filtered_data['timestamp'] - start_time).dt.total_seconds()\n",
    "    filtered_data = filtered_data.set_index('timestamp').resample('15s').mean().reset_index()\n",
    "    filtered_data = filtered_data.dropna()\n",
    "    avg_cpu_usage = filtered_data['cpu_usage'].mean()\n",
    "    return filtered_data, avg_cpu_usage\n",
    "\n",
    "container_ids = ['stockproject-web-1', 'stockproject-db-1', 'stockproject-db_test-1', 'stockproject-locust-1', 'stockproject-celery_worker_execute_transactions-1']\n",
    "output_paths = [\n",
    "    'testCharts/users/cpu',\n",
    "    'testCharts/requestTimes/cpu',\n",
    "    'testCharts/transactionTime/cpu',\n",
    "    'testCharts/numTrade/cpu',\n",
    "    'testCharts/usersClass/cpu',\n",
    "    'testCharts/none/cpu',\n",
    "    'testCharts/usersAllClasses/cpu',\n",
    "    'testCharts/requestTimesAllClasses/cpu',\n",
    "    'testCharts/transactionTimeAllClasses/cpu',\n",
    "    'testCharts/numTradeAllClasses/cpu',\n",
    "    'testCharts/usersClassAllClasses/cpu'\n",
    "]\n",
    "for path in output_paths:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "group_sizes = [4,4,4,4,4]\n",
    "index = 0\n",
    "\n",
    "for i, size in enumerate(group_sizes):\n",
    "    files_to_process = file_paths[index:index + size]\n",
    "    labels_to_use = labels[index:index + size]\n",
    "    output_path = output_paths[i]\n",
    "\n",
    "    for container_id in container_ids:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        for file_path, label in zip(files_to_process, labels_to_use):\n",
    "            data, avg_cpu_usage = process_file(file_path, container_id)\n",
    "            print(f'Average usage | {label} | {container_id} : {avg_cpu_usage:.2f}%')\n",
    "            plt.plot(data['relative_time'], data['cpu_usage'], linestyle='-', label=label)\n",
    "\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('CPU usage (%)')\n",
    "        plt.title(f'CPU usage | {container_id}')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        file_name = f'{container_id}_plot.svg'\n",
    "        #plt.savefig(os.path.join(output_path, file_name))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    index += size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAM charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, container_id):\n",
    "    file_path += 'stockApp_cpu.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    filtered_data = data[data['contener_id'] == container_id]\n",
    "    filtered_data = filtered_data[filtered_data['cpu_usage'] >= 0]\n",
    "    filtered_data['timestamp'] = pd.to_datetime(filtered_data['timestamp'])\n",
    "    start_time = filtered_data['timestamp'].min()\n",
    "    filtered_data = filtered_data[['timestamp', 'memory_usage']]\n",
    "    filtered_data['relative_time'] = (filtered_data['timestamp'] - start_time).dt.total_seconds()\n",
    "    filtered_data = filtered_data.set_index('timestamp').resample('15s').mean().reset_index()\n",
    "    filtered_data = filtered_data.dropna()\n",
    "    return filtered_data\n",
    "container_ids = ['stockproject-web-1', 'stockproject-db-1', 'stockproject-db_test-1', 'stockproject-locust-1', 'stockproject-celery_worker_execute_transactions-1']\n",
    "output_paths = [\n",
    "    'testCharts/users/RAM',\n",
    "    'testCharts/requestTimes/RAM',\n",
    "    'testCharts/transactionTime/RAM',\n",
    "    'testCharts/numTrade/RAM',\n",
    "    'testCharts/usersClass/RAM',\n",
    "    'testCharts/none/RAM',\n",
    "    'testCharts/usersAllClasses/RAM',\n",
    "    'testCharts/requestTimesAllClasses/RAM',\n",
    "    'testCharts/transactionTimeAllClasses/RAM',\n",
    "    'testCharts/numTradeAllClasses/RAM',\n",
    "]\n",
    "for path in output_paths:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "group_sizes = [4,4,4,4,4]\n",
    "index = 0\n",
    "\n",
    "for i, size in enumerate(group_sizes):\n",
    "    files_to_process = file_paths[index:index + size]\n",
    "    labels_to_use = labels[index:index + size]\n",
    "    output_path = output_paths[i]\n",
    "\n",
    "    for container_id in container_ids:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        for file_path, label in zip(files_to_process, labels_to_use):\n",
    "            data = process_file(file_path, container_id)\n",
    "            plt.plot(data['relative_time'], data['memory_usage'], linestyle='-', label=label)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('RAM usage (MB)')\n",
    "        plt.title(f'RAM usage | {container_id}')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        file_name = f'{container_id}_plot.svg'\n",
    "        #plt.savefig(os.path.join(output_path, file_name))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    index += size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
