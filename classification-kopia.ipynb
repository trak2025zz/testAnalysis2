{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports packages and assign variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid, RadiusNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import time\n",
    "file_paths = [\n",
    "    'testData/1.10_A_30s_600ms_3/',\n",
    "    'testData/2.50_A_30s_600ms_3/',\n",
    "    'testData/3.90_A_30s_600ms_3/',\n",
    "    'testData/4.130_A_30s_600ms_3/',\n",
    "    'testData/5.60_A_30s_200ms_3/',\n",
    "    'testData/6.60_A_30s_500ms_3/',\n",
    "    'testData/7.60_A_30s_800ms_3/',\n",
    "    'testData/8.60_A_30s_1100ms_3/',\n",
    "    'testData/9.60_A_5s_600ms_3/',\n",
    "    'testData/10.60_A_20s_600ms_3/',\n",
    "    'testData/11.60_A_35s_600ms_3/',\n",
    "    'testData/12.60_A_50s_600ms_3/',\n",
    "    'testData/13.60_A_30s_600ms_2/',\n",
    "    'testData/14.60_A_30s_600ms_4/',\n",
    "    'testData/15.60_A_30s_600ms_6/',\n",
    "    'testData/16.60_A_30s_600ms_8/',\n",
    "    'testData/17.60_A_30s_600ms_3/',\n",
    "    'testData/18.60_A+NA+AZA_30s_600ms_3/',\n",
    "    'testData/19.60_A+NA_30s_600ms_3/',\n",
    "    'testData/20.60_A+AZA_30s_600ms_3/',\n",
    "]\n",
    "file_paths2 = [\n",
    "    'testData/21.10_A+NA+AZA_30s_600ms_3/',\n",
    "    'testData/22.130_A+NA+AZA_30s_600ms_3/',\n",
    "    'testData/23.60_A+NA+AZA_30s_200ms_3/',\n",
    "    'testData/24.60_A+NA+AZA_30s_1100ms_3/',\n",
    "    'testData/25.60_A+NA+AZA_5s_600ms_3/',\n",
    "    'testData/26.60_A+NA+AZA_50s_600ms_3/',\n",
    "    'testData/27.60_A+NA+AZA_30s_600ms_2/',\n",
    "    'testData/28.60_A+NA+AZA_30s_600ms_8/',\n",
    "]\n",
    "\n",
    "labels = [ _[12:-1] if _ [11] == '.' else _[11:-1] for _ in file_paths ]\n",
    "labels2 = [ _[12:-1] if _ [11] == '.' else _[11:-1] for _ in file_paths2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XBG predict parameter (Robiłem w ramach testu czy coś wychodzi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbTree(path, param):\n",
    "    file_path = f'{path}/stockApp_merged_data.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    timestamps = data['timestamp'] \n",
    "    if 'user_class' in data:\n",
    "      data = data.drop(columns=[\"user_class\"])\n",
    "    data = data.drop(columns=['timestamp', 'endpoint_url', \"api_method\",'application_time_trade','database_time_trade','number_of_sell_offers','number_of_buy_offers'])\n",
    "    X = data.drop(columns=[param])\n",
    "    y = data[param]\n",
    "\n",
    "    X_train, X_test, y_train, y_test, timestamps_train, timestamps_test = train_test_split(X, y, timestamps, test_size=0.2, random_state=42)\n",
    "    train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "    test_data = xgb.DMatrix(X_test, label=y_test)\n",
    "    params = {\n",
    "            'tree_method': 'hist', \n",
    "            'device': 'cpu',\n",
    "            'objective': 'reg:squarederror',\n",
    "            'max_depth': 10,\n",
    "            'learning_rate': 0.1,\n",
    "        }\n",
    "    print(\"Train new model...\")\n",
    "    model = xgb.train(params, train_data, num_boost_round=100)\n",
    "\n",
    "    y_pred = model.predict(test_data)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R² score: {r2}')\n",
    "\n",
    "    y_pred = model.predict(test_data)\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Real values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    plt.title('Real vs Predicted')\n",
    "    #plt.show()\n",
    "    '''\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'timestamp': timestamps_test,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    start_time = data['timestamp'].min()\n",
    "    data = data.set_index('timestamp').resample('15s').mean().reset_index()\n",
    "    data['timestamp'] = (data['timestamp'] - start_time).dt.total_seconds()\n",
    "    data = data.dropna()\n",
    "    aggregated = data\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(aggregated.index, aggregated['y_test'], label='Real values', color='blue', linestyle='dashed')\n",
    "    plt.plot(aggregated.index, aggregated['y_pred'], label='Predicted values', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Time(s)')\n",
    "    plt.ylabel(param)\n",
    "    plt.title(f'Real vs Predicted | {param}')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  \n",
    "i = 0 \n",
    "for test_dir in file_paths:\n",
    "              print(labels[i])\n",
    "              xgbTree(test_dir, 'api_time')\n",
    "              xgbTree(test_dir, 'application_time')\n",
    "              xgbTree(test_dir, 'database_time')\n",
    "              i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict user class with various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiClass(path, param,method):\n",
    "    start_time = time.time()\n",
    "    file_path = f'{path}/stockApp_merged_data.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "    classes= sorted(data[param].unique())\n",
    "    mapping = {url: i for i, url in enumerate(classes)}\n",
    "    data['mapped'] = data[param].map(mapping)\n",
    "    if param != 'endpoint_url':\n",
    "      urls = sorted(data['endpoint_url'].unique())\n",
    "      url_mapping = {url: i for i, url in enumerate(urls)}\n",
    "      data['endpoint_url_mapped'] = data['endpoint_url'].map(url_mapping)\n",
    "      data = data[['mapped', 'endpoint_url_mapped', 'application_time', 'database_time', 'api_time', 'cpu_usage_db_test', 'cpu_usage_db', 'cpu_usage_web']]\n",
    "    if param == 'endpoint_url':\n",
    "      data = data[['mapped', 'application_time', 'database_time', 'api_time', 'cpu_usage_db_test', 'cpu_usage_db', 'cpu_usage_web']]\n",
    "    X = data.drop(columns=['mapped'])\n",
    "    y = data['mapped']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42,stratify=y)\n",
    "    if method == 'ExtraTreesClassifier':\n",
    "      model = ExtraTreesClassifier(n_estimators=1000, random_state=42, criterion='gini', max_depth=10, min_samples_split=4, max_features='sqrt', bootstrap=False) \n",
    "    if method == 'DecisionTreeClassifier':\n",
    "      model = DecisionTreeClassifier(random_state=42, max_depth=8, criterion='gini', max_features='sqrt', min_samples_split=8, splitter='best', ccp_alpha=0)\n",
    "    if method == 'KNeighborsClassifier':\n",
    "      model = KNeighborsClassifier(n_neighbors=7, algorithm='auto', leaf_size=20, weights='uniform')\n",
    "    if method == 'LinearSVC':\n",
    "      model = LinearSVC(multi_class='ovr', class_weight='balanced', max_iter=10000, C=10,loss='squared_hinge', penalty='l1', random_state=42)\n",
    "      sc=StandardScaler()\n",
    "      scaler = sc.fit(X_train)\n",
    "      X_train = scaler.transform(X_train)\n",
    "      X_test = scaler.transform(X_test)\n",
    "    if method == 'MLPClassifier':\n",
    "      model = MLPClassifier(random_state=42, alpha=0.0001, learning_rate='constant' , max_iter=200, batch_size=16, hidden_layer_sizes=(120,80,40), solver='adam', activation='relu')\n",
    "      sc=StandardScaler()\n",
    "      scaler = sc.fit(X_train)\n",
    "      X_train = scaler.transform(X_train)\n",
    "      X_test = scaler.transform(X_test)\n",
    "    if method == 'RandomForestClassifier':\n",
    "      model = RandomForestClassifier(max_depth=8, random_state=42, criterion='gini', n_estimators=500, min_samples_split=8, max_features='sqrt', bootstrap=False)\n",
    "    if method == 'Xgb':\n",
    "      model = xgb.XGBClassifier(booster = 'gbtree',objective='multi:softmax',num_class=len(classes),random_state = 42)\n",
    "      param_grid = {\n",
    "        'reg_lambda':[0,0.3,1],\n",
    "        'gamma':[0,1,2],\n",
    "        'grow_policy':['depthwise', 'lossguide'],\n",
    "        'learning_rate':[0.05, 0.3, 0.6], \n",
    "        'max_depth':[8,10,12],\n",
    "        'n_estimators':[100,200,300]\n",
    "      }\n",
    "      #grid = GridSearchCV(model, param_grid, cv=2)\n",
    "      #grid.fit(X_train, y_train)\n",
    "      #print(grid.best_estimator_)\n",
    "      #print(grid.best_params_)\n",
    "      #print(grid.best_score_)  \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #accuracy = accuracy_score(y_test, y_pred)\n",
    "    #f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f'{method} time: {time.time() - start_time}')\n",
    "    #print(f'{method} - Accuracy: {accuracy}')\n",
    "    #print(f'{method} - F1 Score: {f1}')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mapping.keys())\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix | {method}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "i=0    \n",
    "for test_dir in file_paths2:\n",
    "  print(labels2[i])\n",
    "  methods = ['Xgb', 'ExtraTreesClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', 'LinearSVC','MLPClassifier']\n",
    "  for method in methods:\n",
    "    multiClass(test_dir, 'user_class',method)\n",
    "  i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
